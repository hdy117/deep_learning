{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47d08ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhu/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5877a7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提示文本：Artificial intelligence is changing the world by\n",
      "生成结果：Artificial intelligence is changing the world by transforming human behaviors into \"real\" things.\n",
      "The latest study from MIT‒s Artificial Intelligence Research Center at Johns Hopkins University found that humans are turning their brains to artificial-intelligence technologies, which could revolutionize behavior in ways we don't realize\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 1. 加载模型和Tokenizer（GPT类模型用AutoModelForCausalLM）\n",
    "model_name = \"distilgpt2\"  # 轻量版GPT-2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 注意：GPT2的Tokenizer默认没有padding_token，需手动指定（用eos_token替代）\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. 输入提示文本（模型基于此续写）\n",
    "prompt = \"Artificial intelligence is changing the world by\"\n",
    "\n",
    "# 3. 编码提示文本\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 4. 生成文本（关键参数说明）\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=50,  # 生成的新token数量（不含输入长度）\n",
    "    temperature=0.7,  # 随机性：0=确定性，1=随机，越小越稳定\n",
    "    top_k=50,  # 只从概率前50的token中选择\n",
    "    repetition_penalty=1.2,  # 惩罚重复token（避免连续重复）\n",
    "    do_sample=True,  # 启用采样（生成更自然的文本）\n",
    "    pad_token_id=tokenizer.eos_token_id  # 避免警告\n",
    ")\n",
    "\n",
    "# 5. 解码生成结果（skip_special_tokens=True跳过特殊token如<eos>）\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"提示文本：{prompt}\")\n",
    "print(f\"生成结果：{generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
